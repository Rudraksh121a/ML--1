{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a27061-df04-4dda-b24c-3ab9c89ddd43",
   "metadata": {},
   "source": [
    "# Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its  application. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ead653-c880-4ac6-9da7-2c58a68022b5",
   "metadata": {},
   "source": [
    "Data Scaling is a data preprocessing step for numerical features. Many machine learning algorithms like Gradient descent methods, KNN algorithm, linear and logistic regression, etc. require data scaling to produce good results. Various scalers are defined for this purpose. This article concentrates on Standard Scaler and Min-Max scaler. The task here is to discuss what they mean and how they are implemented using in-built functions that come with this package.\n",
    "\n",
    "Apart from supporting library functions other functions that will be used to achieve the functionality are:\n",
    "\n",
    "    The fit(data) method is used to compute the mean and std dev for a given feature so that it can be used further for scaling.\n",
    "    The transform(data) method is used to perform scaling using mean and std dev calculated using the .fit() method.\n",
    "    The fit_transform() method does both fit and transform.\n",
    "\n",
    "Standard Scaler\n",
    "\n",
    "Standard Scaler helps to get standardized distribution, with a zero mean and standard deviation of one (unit variance). It standardizes features by subtracting the mean value from the feature and then dividing the result by feature standard deviation. \n",
    "\n",
    "The standard scaling is calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6cd07-41e9-4516-a346-128afd98f024",
   "metadata": {},
   "source": [
    "# Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?  Provide an example to illustrate its application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bcd4fe-2b7b-481c-9f5a-3a33c6329799",
   "metadata": {},
   "source": [
    "like Min-Max Scaling, the Unit Vector technique produces values of range [0,1]. When dealing with features with hard boundaries, this is quite useful. For example, when dealing with image data, the colors can range from only 0 to 255. If we plot, then it would look as below for L1 and L2 norm, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c17f97d-c032-46ef-ae11-900d6ad0cda5",
   "metadata": {},
   "source": [
    "# Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an  example to illustrate its application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b8fa09-664e-43cf-a6fd-3e357b65c58c",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a powerful technique used in data analysis, particularly for reducing the dimensionality of datasets while preserving crucial information. It does this by transforming the original variables into a set of new, uncorrelated variables called principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cba9ec-c945-456d-be91-e19e602c6086",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature  Extraction? Provide an example to illustrate this concept. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede726fa-4f72-4105-be1b-1d35eae7e6c3",
   "metadata": {},
   "source": [
    "Feature extraction: PCA can be used to identify the most important features in a dataset, which can be used to build predictive models. Visualization: PCA can be used to visualize high-dimensional data in two or three dimensions, making it easier to understand and interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6293f8-d013-4cc5-baf8-5b3dc51a6f3f",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset  contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to  preprocess the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b1385-6720-4ec8-a4de-c9b3f3bc9899",
   "metadata": {},
   "source": [
    "How do you create a food recommendation system?\n",
    "In order to build an ingredient and recipe recommendation system, it was fundamental to represent them as vectors. This would allow to mathematically calculate their context similarities. The Word2Vec model was trained using Recipe1M+ and K&N datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a4a75-9aa9-48be-9a68-75e4dbaf349f",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many  features, such as company financial data and market trends. Explain how you would use PCA to reduce the  dimensionality of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6cda7-0869-401b-a16c-c7338387c77b",
   "metadata": {},
   "source": [
    "Machine learning models such as Recurrent Neural Networks (RNNs) or LSTMs are popular models applied to predicting time series data such as weather forecasting, election results, house prices, and, of course, stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05abff-5006-4c76-8a40-c86eba9bea4f",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the  values to a range of -1 to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59695ce9-80c9-4375-a5d6-dd0158c0ce08",
   "metadata": {},
   "source": [
    "The cost of having this bounded range - in contrast to standardization - is that we will end up with smaller standard deviations, which can suppress the effect of outliers. A Min-Max scaling is typically done via the following equation: Xsc=X−XminXmax−Xmin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bef2bc-5138-49f9-a6d4-121fffbae6e2",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform  Feature Extraction using PCA. How many principal components would you choose to retain, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65a097-0e2e-4344-a1f4-d29a65036be2",
   "metadata": {},
   "source": [
    "PCA tells us what features are more important, how? In short: We find the first principal component one (PC1). Now PC1 is a linear combination of the variables (features). The variable with the highest weight (coefficient)(loading scores) in the linear equation is the most important feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908fd1b-3b5d-4975-b35a-57ff8d487a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
